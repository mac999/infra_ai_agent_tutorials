{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15982,
     "status": "ok",
     "timestamp": 1745648409266,
     "user": {
      "displayName": "Taewook Kang",
      "userId": "11578752810222612195"
     },
     "user_tz": -540
    },
    "id": "8RTDUpdwtahZ",
    "outputId": "65b5ee75-2084-43a7-a215-9e6e54d5ef06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46.3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import transformers, torch\n",
    "from transformers import pipeline\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1745648439089,
     "user": {
      "displayName": "Taewook Kang",
      "userId": "11578752810222612195"
     },
     "user_tz": -540
    },
    "id": "FDcvLbz2wOJt",
    "outputId": "ef8ef0e1-d05f-429e-a286-9e6de9ec4637"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998830556869507}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9998018145561218}]\n"
     ]
    }
   ],
   "source": [
    "# 감성 분류 파이프라인 생성 (미세조정된 BERT 불러오기)\n",
    "clf = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# 문장 하나를 바로 분류\n",
    "print(clf(\"The acting was great and the story was touching.\"))   # → POSITIVE\n",
    "print(clf(\"The plot was boring and the pacing was slow.\"))       # → NEGATIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER (Named-entity recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb705409434d8982c659b2920bfeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3c891c02374a71938b5ed719c24f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea16219887c04d788aef916fe6dfb524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380da510d47f4b44907019acb1859c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9029b6ba4b6d484183a633efc8d6e071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e910bf8688447c4bf62651c91d6127f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Wolfgang, Score: 1.00, Label: B-PER\n",
      "Entity: Berlin, Score: 1.00, Label: B-LOC\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "for entity in ner_results:\n",
    "\tprint(f\"Entity: {entity['word']}, Score: {entity['score']:.2f}, Label: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Sylvain and I work at Hugging Face in Brooklyn.\n",
      "[{'entity': 'B-PER', 'score': 0.9986273, 'index': 4, 'word': 'S', 'start': 11, 'end': 12}, {'entity': 'B-PER', 'score': 0.93460417, 'index': 5, 'word': '##yl', 'start': 12, 'end': 14}, {'entity': 'B-PER', 'score': 0.7915617, 'index': 6, 'word': '##va', 'start': 14, 'end': 16}, {'entity': 'B-PER', 'score': 0.90470797, 'index': 7, 'word': '##in', 'start': 16, 'end': 18}, {'entity': 'B-ORG', 'score': 0.96700376, 'index': 12, 'word': 'Hu', 'start': 33, 'end': 35}, {'entity': 'B-ORG', 'score': 0.88534623, 'index': 13, 'word': '##gging', 'start': 35, 'end': 40}, {'entity': 'I-ORG', 'score': 0.9884615, 'index': 14, 'word': 'Face', 'start': 41, 'end': 45}, {'entity': 'B-LOC', 'score': 0.9971419, 'index': 16, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n",
      "Entity: S, Score: 1.00, Label: B-PER\n",
      "Entity: ##yl, Score: 0.93, Label: B-PER\n",
      "Entity: ##va, Score: 0.79, Label: B-PER\n",
      "Entity: ##in, Score: 0.90, Label: B-PER\n",
      "Entity: Hu, Score: 0.97, Label: B-ORG\n",
      "Entity: ##gging, Score: 0.89, Label: B-ORG\n",
      "Entity: Face, Score: 0.99, Label: I-ORG\n",
      "Entity: Brooklyn, Score: 1.00, Label: B-LOC\n"
     ]
    }
   ],
   "source": [
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "print(example)\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)\n",
    "for entity in ner_results:\n",
    "\tprint(f\"Entity: {entity['word']}, Score: {entity['score']:.2f}, Label: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for the word 'feel': [ 0.07380505 -0.01533471 -0.04536613  0.06554051 -0.0486016  -0.01816018\n",
      "  0.0287658   0.00991874 -0.08285215 -0.09448818]\n"
     ]
    }
   ],
   "source": [
    "# Example text data\n",
    "sentences = [\n",
    "    \"I feel good today\",\n",
    "    \"The weather is clear and warm today\",\n",
    "    \"I ate kimchi for lunch\",\n",
    "    \"Exercising makes me feel better\"\n",
    "]\n",
    "\n",
    "# Preprocess text data (split words by spaces)\n",
    "sentences = [sentence.split() for sentence in sentences]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=10, window=3, min_count=1, sg=0)\n",
    "\n",
    "# Check the vector for a specific word\n",
    "vector = model.wv['feel']\n",
    "print(\"Vector for the word 'feel':\", vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'feel': [('today', 0.5436006188392639), ('warm', 0.35868826508522034), ('I', 0.32933861017227173)]\n"
     ]
    }
   ],
   "source": [
    "# Find similar words\n",
    "similar_words = model.wv.most_similar('feel', topn=3)\n",
    "print(\"Words similar to 'feel':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOM61AJo22tIfkuMPJDhZ8O",
   "gpuType": "T4",
   "mount_file_id": "1CsdjSRIYSt8e9qW4XawKFRXiq9JZNXFf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_lmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
